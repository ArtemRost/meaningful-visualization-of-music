{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11763043,"sourceType":"datasetVersion","datasetId":7359504,"isSourceIdPinned":true}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nimport random\n\nfrom transformers import BertConfig, BertModel, Trainer, TrainingArguments\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:11.732186Z","iopub.execute_input":"2025-05-20T10:41:11.732542Z","iopub.status.idle":"2025-05-20T10:41:20.257912Z","shell.execute_reply.started":"2025-05-20T10:41:11.732515Z","shell.execute_reply":"2025-05-20T10:41:20.256766Z"}},"outputs":[{"name":"stderr","text":"2025-05-20 10:41:16.726479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747737676.749083     194 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747737676.756519     194 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"90"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_parquet('/kaggle/input/small-music-genre-dataset/dataset/train.parquet')\nval_df = pd.read_parquet('/kaggle/input/small-music-genre-dataset/dataset/val.parquet')\ntest_df = pd.read_parquet('/kaggle/input/small-music-genre-dataset/dataset/test.parquet')\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.259209Z","iopub.execute_input":"2025-05-20T10:41:20.259752Z","iopub.status.idle":"2025-05-20T10:41:20.284989Z","shell.execute_reply.started":"2025-05-20T10:41:20.259728Z","shell.execute_reply":"2025-05-20T10:41:20.284426Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    main_genre                        spec_path\n0    classical   ./dataset/spectrograms/332.npy\n1          ska  ./dataset/spectrograms/2882.npy\n2      country   ./dataset/spectrograms/421.npy\n3     afrobeat    ./dataset/spectrograms/79.npy\n4  psychedelic    ./dataset/spectrograms/41.npy","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>main_genre</th>\n      <th>spec_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>classical</td>\n      <td>./dataset/spectrograms/332.npy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ska</td>\n      <td>./dataset/spectrograms/2882.npy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>country</td>\n      <td>./dataset/spectrograms/421.npy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>afrobeat</td>\n      <td>./dataset/spectrograms/79.npy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>psychedelic</td>\n      <td>./dataset/spectrograms/41.npy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"def fix_path(x):\n    return x.replace('.', '/kaggle/input/small-music-genre-dataset', 1)\n\ntrain_df['spec_path'] = train_df['spec_path'].apply(fix_path)\nval_df['spec_path'] = val_df['spec_path'].apply(fix_path)\ntest_df['spec_path'] = test_df['spec_path'].apply(fix_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.285633Z","iopub.execute_input":"2025-05-20T10:41:20.285888Z","iopub.status.idle":"2025-05-20T10:41:20.292683Z","shell.execute_reply.started":"2025-05-20T10:41:20.285842Z","shell.execute_reply":"2025-05-20T10:41:20.292097Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Dataset and Model classes","metadata":{}},{"cell_type":"markdown","source":"### Dataset def","metadata":{}},{"cell_type":"code","source":"class SpectrogramDataset(Dataset):\n    def __init__(self, \n                dataframe, \n                genre2label,\n                transform=None,\n                # Параметры аугментаций\n                time_mask_param=15,\n                freq_mask_param=8,\n                noise_level=0.005,\n                mixup_alpha=0.4):\n        \n        self.df = dataframe.reset_index(drop=True)\n        self.genre2label = genre2label\n        self.transform = transform\n        \n        # Параметры аугментаций\n        self.time_mask_param = time_mask_param\n        self.freq_mask_param = freq_mask_param\n        self.noise_level = noise_level\n        self.mixup_alpha = mixup_alpha\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # Основная загрузка данных\n        row = self.df.iloc[idx]\n        spec = np.load(row['spec_path']).astype(np.float32)\n        attention_mask = torch.ones(spec.shape[0], dtype=torch.long)\n        label = self.genre2label[row['main_genre']]\n\n        # Аугментации (применяются с вероятностью 70%)\n        if self.transform and random.random() < 0.7:\n            # 1. Временное маскирование\n            spec = self.time_mask(spec)\n            \n            # 2. Частотное маскирование\n            spec = self.frequency_mask(spec)\n            \n            # 3. Добавление шума\n            spec = self.add_gaussian_noise(spec)\n            \n            # 4. Случайный временной сдвиг\n            spec, attention_mask = self.random_time_shift(spec, attention_mask)\n            \n            # 5. Mixup аугментация\n            if random.random() < 0.3:  # 30% вероятность\n                spec, label = self.mixup(spec, label, idx)\n\n        return {\n            \"spectrogram\": torch.tensor(spec, dtype=torch.float32),\n            \"attention_mask\": attention_mask,\n            \"labels\": torch.tensor(label, dtype=torch.long)\n        }\n\n    def time_mask(self, spec):\n        max_mask_length = int(spec.shape[0] * 0.2)  # Макс. 20% длины\n        mask_length = random.randint(1, min(self.time_mask_param, max_mask_length))\n        mask_start = random.randint(0, spec.shape[0] - mask_length)\n        spec[mask_start:mask_start+mask_length, :] = 0\n        return spec\n\n    def frequency_mask(self, spec):\n        mask_length = random.randint(1, self.freq_mask_param)\n        mask_start = random.randint(0, spec.shape[1] - mask_length)\n        spec[:, mask_start:mask_start+mask_length] = 0\n        return spec\n\n    def add_gaussian_noise(self, spec):\n        noise = np.random.normal(0, self.noise_level, spec.shape)\n        return np.clip(spec + noise, 0, 1)\n\n    def random_time_shift(self, spec, mask):\n        shift = random.randint(-int(spec.shape[0]*0.1), int(spec.shape[0]*0.1))\n        if shift > 0:\n            spec = np.pad(spec, ((shift,0), (0,0)), mode='constant')[:-shift]\n            mask = torch.cat([mask[shift:], torch.zeros(shift, dtype=torch.long)])\n        elif shift < 0:\n            spec = np.pad(spec, ((0,-shift), (0,0)), mode='constant')[-shift:]\n            mask = torch.cat([torch.zeros(-shift, dtype=torch.long), mask[:shift]])\n        return spec, mask\n\n    def mixup(self, spec1, label1, idx1):\n        idx2 = random.randint(0, len(self)-1)\n        row2 = self.df.iloc[idx2]\n        spec2 = np.load(row2['spec_path']).astype(np.float32)\n        label2 = self.genre2label[row2['main_genre']]\n        \n        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n        mixed_spec = lam * spec1 + (1 - lam) * spec2\n        mixed_label = lam * label1 + (1 - lam) * label2\n        \n        return mixed_spec, mixed_label\n\n    def random_scaling(self, spec):\n        scale_factor = random.choice([\n            lambda x: x * random.uniform(0.8, 1.2),      # Амплитудное масштабирование\n            lambda x: np.log1p(x * random.uniform(0.5, 2)),  # Нелинейное преобразование\n            lambda x: x ** random.uniform(0.5, 1.5)      # Степенное преобразование\n        ])\n        return np.clip(scale_factor(spec), 0, 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.294567Z","iopub.execute_input":"2025-05-20T10:41:20.294814Z","iopub.status.idle":"2025-05-20T10:41:20.309800Z","shell.execute_reply.started":"2025-05-20T10:41:20.294797Z","shell.execute_reply":"2025-05-20T10:41:20.309150Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Model def","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\n\nclass SpectrogramBertClassifier(nn.Module):\n    def __init__(self, input_feature_dim, num_labels, mlm_prob, bert_config):\n        super().__init__()\n        self.mlm_prob = mlm_prob\n        self.num_labels = num_labels\n        self.bert_config = bert_config\n\n        # Parameters for masking patches (tweak these if needed)\n        self.min_patch_len = 5\n        self.max_patch_len = 25\n        \n        # Projection of spectrograms\n        self.projection = nn.Linear(input_feature_dim, bert_config.hidden_size)\n        self.norm = nn.LayerNorm(bert_config.hidden_size)\n        \n        # BERT components\n        self.bert = BertModel(bert_config)\n        # Инициализируем mask token: можно добавить небольшое отклонение\n        self.mask_token = nn.Parameter(torch.zeros(bert_config.hidden_size))\n        \n        # CLS token как обучаемый параметр с контролируемой инициализацией\n        self.cls_token = nn.Parameter(torch.randn(1, 1, bert_config.hidden_size))\n        nn.init.normal_(self.cls_token, std=bert_config.initializer_range)\n        \n        # Упрощённая классификационная голова\n        self.classifier = nn.Linear(bert_config.hidden_size, num_labels)\n        self.classifier.weight.data.normal_(mean=0.0, std=bert_config.initializer_range)\n        self.classifier.bias.data.zero_()\n\n        # MLM head (если требуется)\n        self.mlm_norm = nn.LayerNorm(bert_config.hidden_size)\n        self.mlm_head = nn.Linear(bert_config.hidden_size, input_feature_dim)\n        self.loss_fct = nn.CrossEntropyLoss()\n\n    def _create_patch_mask(self, batch_size, seq_len, attention_mask):\n        \"\"\"Улучшенное маскирование с защитой границ\"\"\"\n        device = attention_mask.device\n        mask = torch.zeros(batch_size, seq_len, dtype=torch.bool, device=device)\n        \n        for b in range(batch_size):\n            valid_indices = torch.where(attention_mask[b])[0]\n            if len(valid_indices) < self.min_patch_len:\n                continue\n                \n            # Динамическое количество патчей\n            max_possible = len(valid_indices) // self.min_patch_len\n            num_patches = min(max(1, int(self.mlm_prob * seq_len / self.min_patch_len)), max_possible)\n            \n            for _ in range(num_patches):\n                patch_len = torch.randint(self.min_patch_len, self.max_patch_len + 1, (1,)).item()\n                # Если оставшихся валидных индексов меньше, чем длина патча – пропускаем итерацию\n                if len(valid_indices) < patch_len:\n                    continue\n                    \n                start = torch.randint(0, len(valid_indices) - patch_len + 1, (1,)).item()\n                start_idx = valid_indices[start].item()\n                end_idx = min(start_idx + patch_len, seq_len)\n                \n                # Защита первых/последних 10% кадров\n                if start_idx < seq_len * 0.1 or end_idx > seq_len * 0.9:\n                    continue\n                    \n                mask[b, start_idx:end_idx] = True\n                \n        return mask\n\n    def forward(self, spectrogram, attention_mask, labels=None):\n        B, T, _ = spectrogram.size()\n        \n        # 1. Проекция и нормализация\n        projected = self.norm(self.projection(spectrogram))\n        \n        # Если требуются позиционные энкодинги, их можно добавить здесь\n        \n        # 2. Добавление CLS токена\n        cls_tokens = self.cls_token.expand(B, -1, -1)\n        # Собираем эмбеддинги: CLS токен + проекции\n        inputs_embeds = torch.cat([cls_tokens, projected], dim=1)\n        \n        # 3. Создание маски для патчей и применение mask token\n        patch_mask = self._create_patch_mask(B, T, attention_mask)\n        # Получаем эмбеддинги без CLS токена, делаем клон для безопасного in-place изменения\n        embeds_without_cls = inputs_embeds[:, 1:].clone()\n        # Применяем маску: там, где patch_mask==True, заменяем на mask_token\n        embeds_without_cls[patch_mask] = self.mask_token\n        # Собираем итоговый тензор с обновленными эмбеддингами\n        inputs_embeds = torch.cat([cls_tokens, embeds_without_cls], dim=1)\n        \n        # 4. Расширяем маску внимания для CLS токена\n        extended_mask = torch.cat([\n            torch.ones(B, 1, device=attention_mask.device),\n            attention_mask\n        ], dim=1)\n        \n        # 5. Пропуск через BERT\n        outputs = self.bert(\n            inputs_embeds=inputs_embeds,\n            attention_mask=extended_mask\n        )\n        \n        \n        hidden_states = outputs.last_hidden_state[:, 1:]\n        mlm_predictions = self.mlm_head(self.mlm_norm(hidden_states))\n\n        # for r^2 metrics\n        mlm_targets = spectrogram[patch_mask]\n        mlm_preds = mlm_predictions[patch_mask]\n\n        cls_output = outputs.last_hidden_state[:, 0]\n        classification_logits = self.classifier(cls_output)\n        \n        # 7. Вычисление потерь\n        loss_dict = {}\n        if labels is not None:\n\n            # Расчет accuracy\n            predicted_labels = torch.argmax(classification_logits, dim=-1)\n            accuracy = (predicted_labels == labels).float().mean().cpu().detach().numpy()\n            \n            classification_loss = self.loss_fct(classification_logits, labels)\n            mlm_loss = F.mse_loss(mlm_predictions[patch_mask], spectrogram[patch_mask])\n\n            # R² Calculation\n            ss_res = torch.sum((mlm_targets - mlm_preds)**2)\n            ss_tot = torch.sum((mlm_targets - torch.mean(mlm_targets))**2)\n            r_squared = 1.0 - (ss_res / (ss_tot + 1e-8)).cpu().detach().numpy()  # Добавлен epsilon для стабильности\n            \n            \n            loss = 0.5 * classification_loss + 0.5 * mlm_loss \n            \n            loss_dict = {\n                \"loss\": loss,\n                \"classification_loss\": classification_loss,\n                \"mlm_loss\": mlm_loss,\n                \"accuracy\": accuracy,\n                \"r_squared\": r_squared\n            }\n    \n        return {\n            **loss_dict,\n            \"cls_embedding\": cls_output.detach(),\n            \"classification_logits\": classification_logits,\n            \"mlm_predictions\": mlm_predictions,\n            \"patch_mask\": patch_mask\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.310465Z","iopub.execute_input":"2025-05-20T10:41:20.310675Z","iopub.status.idle":"2025-05-20T10:41:20.329249Z","shell.execute_reply.started":"2025-05-20T10:41:20.310650Z","shell.execute_reply":"2025-05-20T10:41:20.328539Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"### Data prep","metadata":{}},{"cell_type":"code","source":"# mapping from genre to integer label for training\nunique_genres = pd.concat([train_df['main_genre'], val_df['main_genre'], test_df['main_genre']]).unique()\ngenre2label = {genre: idx for idx, genre in enumerate(unique_genres)}\nnum_labels = len(genre2label)\n\n\ntrain_dataset = SpectrogramDataset(\n    dataframe=train_df,\n    genre2label=genre2label,\n    transform=True,\n    time_mask_param=2,    # Макс. длина временной маски\n    freq_mask_param=2,    # Макс. ширина частотной маски\n    noise_level=0.01,      \n    mixup_alpha=0.1       \n)\nval_dataset = SpectrogramDataset(val_df, genre2label)\ntest_dataset = SpectrogramDataset(test_df, genre2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.330020Z","iopub.execute_input":"2025-05-20T10:41:20.330245Z","iopub.status.idle":"2025-05-20T10:41:20.347339Z","shell.execute_reply.started":"2025-05-20T10:41:20.330223Z","shell.execute_reply":"2025-05-20T10:41:20.346758Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# input feature dimension (F).\nexample_spec = np.load(train_df.loc[4, 'spec_path']).astype(np.float32)\ninput_feature_dim = example_spec.shape[1]\n\nprint(input_feature_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.348020Z","iopub.execute_input":"2025-05-20T10:41:20.348276Z","iopub.status.idle":"2025-05-20T10:41:20.369165Z","shell.execute_reply.started":"2025-05-20T10:41:20.348251Z","shell.execute_reply":"2025-05-20T10:41:20.368457Z"}},"outputs":[{"name":"stdout","text":"1292\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Device choice","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.369727Z","iopub.execute_input":"2025-05-20T10:41:20.369938Z","iopub.status.idle":"2025-05-20T10:41:20.373524Z","shell.execute_reply.started":"2025-05-20T10:41:20.369920Z","shell.execute_reply":"2025-05-20T10:41:20.372658Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Model config and init","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig\n\ncustom_config = BertConfig(\n    vocab_size=1,  \n    hidden_size=768,\n    num_hidden_layers=8,\n    num_attention_heads=8,\n    intermediate_size=2048,\n    max_position_embeddings=2048,\n)\n\n\nmodel = SpectrogramBertClassifier(\n    input_feature_dim=input_feature_dim,\n    num_labels=num_labels,\n    mlm_prob=0.15,\n    bert_config=custom_config\n)\n\n\nmodel.to(device)\nprint(\"Using device:\", device)\n\n\ndef data_collator(features):\n    batch = {}\n    # padding\n    batch[\"spectrogram\"] = torch.nn.utils.rnn.pad_sequence(\n        [f[\"spectrogram\"] for f in features], batch_first=True, padding_value=0.0\n    )\n    batch[\"attention_mask\"] = torch.nn.utils.rnn.pad_sequence(\n        [f[\"attention_mask\"] for f in features], batch_first=True, padding_value=0\n    )\n    batch[\"labels\"] = torch.stack([f[\"labels\"] for f in features])\n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:20.374353Z","iopub.execute_input":"2025-05-20T10:41:20.374568Z","iopub.status.idle":"2025-05-20T10:41:21.270314Z","shell.execute_reply.started":"2025-05-20T10:41:20.374553Z","shell.execute_reply":"2025-05-20T10:41:21.269463Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### WANDB init","metadata":{}},{"cell_type":"code","source":"import wandb\nwandb.login(key='f9e64e1618bc54c2c1fae6cfae56e2905541c9cb')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:21.272813Z","iopub.execute_input":"2025-05-20T10:41:21.273136Z","iopub.status.idle":"2025-05-20T10:41:27.814484Z","shell.execute_reply.started":"2025-05-20T10:41:21.273118Z","shell.execute_reply":"2025-05-20T10:41:27.813725Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mostgot\u001b[0m (\u001b[33mkomandakomanda\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_PROJECT\"]=\"audio-bert-final\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:27.815338Z","iopub.execute_input":"2025-05-20T10:41:27.816247Z","iopub.status.idle":"2025-05-20T10:41:27.819315Z","shell.execute_reply.started":"2025-05-20T10:41:27.816226Z","shell.execute_reply":"2025-05-20T10:41:27.818741Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"### HF Trainer setup and training","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport math\nimport torch\nfrom transformers import Trainer, TrainingArguments\n\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        outputs = model(**inputs)\n        loss = outputs.get(\"loss\")\n        return (loss, outputs) if return_outputs else loss\n\n    def training_step(self, model, inputs, p):\n        model.train()\n        loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n        loss.backward()\n\n        # Логирование метрик для классификации и MLM\n        logs = {\n            \"train_loss\": loss.item(),\n            \"train_mlm_loss\": outputs.get(\"mlm_loss\", 0).item(),\n            \"train_classification_loss\": outputs.get(\"classification_loss\", 0).item(),\n            \"train_accuracy\": outputs.get(\"accuracy\", 0),\n            \"train_r_squared\": outputs.get(\"r_squared\", 0)\n        }\n        self.log(logs)\n        return loss.detach()\n\n    def evaluation_step(self, model, inputs):\n        with torch.no_grad():\n            outputs = model(**inputs)\n        \n        return {\n            \"loss\": outputs.get(\"loss\").item() if outputs.get(\"loss\") is not None else None,\n            \"mlm_loss\": outputs.get(\"mlm_loss\", 0).item(),\n            \"classification_loss\": outputs.get(\"classification_loss\", 0).item(),\n            \"accuracy\": outputs.get(\"accuracy\", 0),\n            \"r_squared\": outputs.get(\"r_squared\", 0)\n        }\n\n    def evaluate(self, eval_dataset=None, metric_key_prefix=\"eval\", **kwargs):\n        eval_dataloader = self.get_eval_dataloader(eval_dataset)\n        \n        metric_keys = [\"loss\", \"mlm_loss\", \"classification_loss\", \"accuracy\", \"r_squared\"]\n        all_metrics = {k: [] for k in metric_keys}\n\n        for inputs in eval_dataloader:\n            batch_metrics = self.evaluation_step(self.model, inputs)\n            for k in metric_keys:\n                if batch_metrics[k] is not None:\n                    all_metrics[k].append(batch_metrics[k])\n\n        # Агрегация метрик, исключая NaN\n        eval_metrics = {}\n        for k in metric_keys:\n            values = [v for v in all_metrics[k] if not math.isnan(v)]\n            if values:\n                eval_metrics[f\"{metric_key_prefix}_{k}\"] = np.mean(values)\n        \n        self.log(eval_metrics)\n        return eval_metrics\n\n\nfrom transformers import TrainerCallback\n\nclass DistributionMonitor(TrainerCallback):\n    def on_evaluate(self, args, state, control, **kwargs):\n        model.eval()\n        with torch.no_grad():\n            sample = next(iter(val_dataloader))\n            outputs = model(**sample)\n            \n            # CLS vs среднее проекций\n            plt.figure(figsize=(12,5))\n            plt.subplot(121)\n            plt.hist(outputs[\"cls_embedding\"].cpu().numpy().flatten(), bins=50, alpha=0.5, label='CLS')\n            plt.hist(outputs[\"mlm_predictions\"].cpu().numpy().flatten(), bins=50, alpha=0.5, label='MLM')\n            plt.legend()\n            \n            # Градиентные распределения\n            plt.subplot(122)\n            grads = [p.grad.cpu().numpy().flatten() for p in model.parameters() if p.grad is not None]\n            plt.hist(np.concatenate(grads), bins=100, log=True)\n            plt.title(\"Gradient Distribution\")\n            plt.show()\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=15,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    logging_steps=3,\n    eval_steps=3,\n    learning_rate=5e-4,\n    weight_decay=0.01,\n    eval_strategy='steps',\n    report_to=\"wandb\",\n    run_name=\"audio-bert-classification-acc-r2-2\",\n)\n\n# Создаем кастомный тренер\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,\n)\n\ntrainer.add_callback(DistributionMonitor())\n\n# Запускаем обучение\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:41:27.820083Z","iopub.execute_input":"2025-05-20T10:41:27.820347Z","iopub.status.idle":"2025-05-20T11:36:13.478256Z","shell.execute_reply.started":"2025-05-20T10:41:27.820325Z","shell.execute_reply":"2025-05-20T11:36:13.476682Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_104128-2dsb6420</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/komandakomanda/audio-bert-final/runs/2dsb6420' target=\"_blank\">audio-bert-classification-acc-r2-2</a></strong> to <a href='https://wandb.ai/komandakomanda/audio-bert-final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/komandakomanda/audio-bert-final' target=\"_blank\">https://wandb.ai/komandakomanda/audio-bert-final</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/komandakomanda/audio-bert-final/runs/2dsb6420' target=\"_blank\">https://wandb.ai/komandakomanda/audio-bert-final/runs/2dsb6420</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='501' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [501/525 54:32 < 02:37, 0.15 it/s, Epoch 14.29/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_194/524985914.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Запускаем обучение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2625\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msteps_skipped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2627\u001b[0;31m                         self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2628\u001b[0m                             \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m                             \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3226\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful_callbacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3228\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAINER_STATE_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36msave_to_json\u001b[0;34m(self, json_path)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;34m\"\"\"Save the content of this instance in JSON format inside `json_path`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    181\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"],"ename":"TypeError","evalue":"Object of type ndarray is not JSON serializable","output_type":"error"}],"execution_count":12},{"cell_type":"markdown","source":"# Evaluating work","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_hist_df = pd.DataFrame(trainer.state.log_history)\n\ntrain_hist_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:36:13.478928Z","iopub.status.idle":"2025-05-20T11:36:13.479260Z","shell.execute_reply.started":"2025-05-20T11:36:13.479098Z","shell.execute_reply":"2025-05-20T11:36:13.479113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.lineplot(train_hist_df[['step', 'loss', 'eval_loss']].set_index('step'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:36:13.480278Z","iopub.status.idle":"2025-05-20T11:36:13.480491Z","shell.execute_reply.started":"2025-05-20T11:36:13.480389Z","shell.execute_reply":"2025-05-20T11:36:13.480398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.lineplot(train_hist_df[['step', 'eval_cls_loss', 'eval_mlm_loss']].set_index('step'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:36:13.481979Z","iopub.status.idle":"2025-05-20T11:36:13.482296Z","shell.execute_reply.started":"2025-05-20T11:36:13.482120Z","shell.execute_reply":"2025-05-20T11:36:13.482136Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CLS embedding analysis","metadata":{}},{"cell_type":"code","source":"! ls results/checkpoint-770","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:36:13.483391Z","iopub.status.idle":"2025-05-20T11:36:13.483686Z","shell.execute_reply.started":"2025-05-20T11:36:13.483545Z","shell.execute_reply":"2025-05-20T11:36:13.483559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3 genres","metadata":{}},{"cell_type":"code","source":"genres = 3\nloaders = []\n\nfor i in range(genres):\n    tmp_df = test_df[test_df['main_genre'] == test_df['main_genre'].unique()[i]]\n    dataset = SpectrogramDataset(tmp_df, genre2label)\n    loader = DataLoader(dataset, batch_size=8, collate_fn=data_collator)\n    loaders.append(loader)\n\n\nall_cls, all_labels = [], []\n\nfor loader in loaders:\n    # Сбор эмбеддингов и меток\n    \n    for batch in tqdm(loader):\n        \n        batch = {k: v.to(device) for k, v in batch.items()}\n        labels = batch['labels']\n        batch.pop('labels')\n    \n        outputs = model(**batch)\n        all_cls.append(outputs[\"cls_embedding\"].cpu())\n        all_labels.append(labels.cpu())\n\nall_cls = torch.cat(all_cls)\nall_labels = torch.cat(all_labels)\n    \n# Визуализация через PCA\n    \npca = PCA(n_components=2)\ncls_2d = pca.fit_transform(all_cls.detach().numpy())\n    \nplt.scatter(cls_2d[:, 0], cls_2d[:, 1], c=all_labels.numpy(), cmap='viridis')\nplt.title(\"PCA [CLS] Embeddings\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! pip install umap-learn -q\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import umap\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Преобразование тензора в numpy array (предполагаем, что all_cls и all_labels уже определены)\ncls_embeddings = all_cls.detach().numpy()\nlabels = all_labels.numpy()\n\n# Инициализация и применение UMAP с оптимальными параметрами\numap_reducer = umap.UMAP(\n    n_components=2,\n    n_neighbors=15,          # Оптимально для баланса локальных/глобальных структур\n    min_dist=0.1,            # Плотность кластеров\n    metric='cosine',         # Лучше всего для эмбеддингов\n    random_state=42          # Репроизводимость\n)\ncls_2d_umap = umap_reducer.fit_transform(cls_embeddings)\n\n# Настройка визуализации\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(\n    cls_2d_umap[:, 0], \n    cls_2d_umap[:, 1],\n    c=labels,\n    cmap='viridis',\n    s=25,                    # Размер точек\n    alpha=0.7,               # Прозрачность\n    edgecolor='none'         # Убираем границы точек\n)\n\n# Дополнительные элементы графика\nplt.title('UMAP Projection of CLS Embeddings', pad=20, fontsize=14)\nplt.xlabel('UMAP Dimension 1', labelpad=10)\nplt.ylabel('UMAP Dimension 2', labelpad=10)\nplt.grid(alpha=0.3)          # Сетка с прозрачностью\n\n# Цветовая легенда\ncbar = plt.colorbar(scatter, pad=0.01)\ncbar.set_label('Class Labels', rotation=270, labelpad=20)\n\n# Оптимизация расположения\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:36:13.491447Z","iopub.status.idle":"2025-05-20T11:36:13.491747Z","shell.execute_reply.started":"2025-05-20T11:36:13.491594Z","shell.execute_reply":"2025-05-20T11:36:13.491608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}